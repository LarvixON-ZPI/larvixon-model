# Classification Model Larvixon

This model performs classification of larvae behavior based on sequences of image frames extracted from video. It predicts the substance that the larvae were injected with, based on visible behavioral patterns.

The architecture combines:

- **CNN (ResNet18)** ‚Äì extracts spatial features from each frame  
- **LSTM** ‚Äì captures temporal dynamics across the frame sequence  
- **Fully Connected Layer** ‚Äì outputs the predicted class

Input: sequence of `N` frames, shape `[N, 3, 112, 112]`  
Output: class label (`substance_a`, `substance_b`, ...)

The model is trained using PyTorch on frame folders grouped by class.

## Manual Use

- Input frames into inference_frames/seq1 directory, in .png format
- Set config variables in evaluate.py
- run python evaluate.py

## ‚öôÔ∏è Configuration

üîπ Variable Explanations

- **FRAME_DIR** ‚Äì path to a folder with frames for inference (prediction).

- **DATA_DIR** ‚Äì root folder containing the dataset used for training/validation, organized by class subfolders.

- **BATCH_SIZE** ‚Äì number of sequences processed in parallel during training/evaluation. Lower it if GPU memory is small (‚â§4 GB ‚Üí use 1‚Äì2).

- **NUM_FRAMES** ‚Äì how many frames per sequence the model uses. Extra frames are cut, fewer frames are padded.

- **NUM_CLASSES** ‚Äì total number of classes (substances) to predict. Must match your dataset.

- **MODEL_PATH** ‚Äì file path where the trained model weights are saved/loaded.

- **DEVICE** ‚Äì automatically selects "cuda" if a GPU is available, otherwise "cpu".

- **CLASS_NAMES** ‚Äì list of human-readable class labels in the order they are mapped during training.
